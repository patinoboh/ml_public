{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8562ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import lzma\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f6b4b3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--train_size'], dest='train_size', nargs=None, const=None, default=1000, type=<class 'int'>, choices=None, required=False, help='Train set size', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# These arguments will be set appropriately by ReCodEx, even if you change them.\n",
    "parser.add_argument(\"--idf\", default=False, action=\"store_true\", help=\"Use IDF weights\")\n",
    "parser.add_argument(\"--recodex\", default=False, action=\"store_true\", help=\"Running in ReCodEx\")\n",
    "parser.add_argument(\"--seed\", default=45, type=int, help=\"Random seed\")\n",
    "parser.add_argument(\"--tf\", default=False, action=\"store_true\", help=\"Use TF weights\")\n",
    "parser.add_argument(\"--test_size\", default=500, type=int, help=\"Test set size\")\n",
    "parser.add_argument(\"--train_size\", default=1000, type=int, help=\"Train set size\")\n",
    "# For these and any other arguments you add, ReCodEx will keep your default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34a458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsGroups:\n",
    "    def __init__(self,\n",
    "                 name=\"20newsgroups.train.pickle\",\n",
    "                 data_size=None,\n",
    "                 url=\"https://ufal.mff.cuni.cz/~courses/npfl129/2324/datasets/\"):\n",
    "        if not os.path.exists(name):\n",
    "            print(\"Downloading dataset {}...\".format(name), file=sys.stderr)\n",
    "            urllib.request.urlretrieve(url + name, filename=\"{}.tmp\".format(name))\n",
    "            os.rename(\"{}.tmp\".format(name), name)\n",
    "\n",
    "        with lzma.open(name, \"rb\") as dataset_file:\n",
    "            dataset = pickle.load(dataset_file)\n",
    "\n",
    "        self.DESCR = dataset.DESCR\n",
    "        self.data = dataset.data[:data_size]\n",
    "        self.target = dataset.target[:data_size]\n",
    "        self.target_names = dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(text):\n",
    "    tf = {}\n",
    "    for word in text.split():\n",
    "        if word in tf:\n",
    "            tf[word] += 1\n",
    "        else:\n",
    "            tf[word] = 1\n",
    "    for key in tf:\n",
    "        if tf[key] == 1:\n",
    "            del tf[key]\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87483adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args: argparse.Namespace) -> float:\n",
    "    # Load the 20newsgroups data.\n",
    "    newsgroups = NewsGroups(data_size=args.train_size + args.test_size)\n",
    "\n",
    "    # Create train-test split.\n",
    "    train_data, test_data, train_target, test_target = sklearn.model_selection.train_test_split(\n",
    "        newsgroups.data, newsgroups.target, test_size=args.test_size, random_state=args.seed)\n",
    "    \n",
    "    # TODO: Create a feature for every term that is present at least twice\n",
    "    # in the training data. A term is every maximal sequence of at least 1 word character,\n",
    "    # where a word character corresponds to a regular expression `\\w`.\n",
    "    terms = [(re.findall(r\"\\w+\", word)) for word in train_data]\n",
    "    test_terms = [(re.findall(r\"\\w+\", word)) for word in test_data]\n",
    "    \n",
    "\n",
    "    # TODO: For each document, compute its features as\n",
    "    # - term frequency (TF), if `args.tf` is set (term frequency is\n",
    "    #   proportional to counts but normalized to sum to 1);\n",
    "    # - otherwise, use binary indicators (1 if a given term is present, else 0)\n",
    "    #\n",
    "    # Then, if `args.idf` is set, multiply the document features by the\n",
    "    # inverse document frequencies (IDF), where\n",
    "    # - use the variant which contains `+1` in the denominator;\n",
    "    # - the IDFs are computed on the train set and then reused without\n",
    "    #   modification on the test set.\n",
    "\n",
    "    # TODO: Train a `sklearn.linear_model.LogisticRegression(solver=\"liblinear\", C=10_000)`\n",
    "    # model on the train set, and classify the test set.\n",
    "\n",
    "    # TODO: Evaluate the test set performance using a macro-averaged F1 score.\n",
    "    f1_score = 0.1\n",
    "\n",
    "    return 100 * f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0ce1604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score for TF=False, IDF=False: 10.0%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = parser.parse_args([] if \"__file__\" not in globals() else None)\n",
    "    f1_score = main(args)\n",
    "    print(\"F-1 score for TF={}, IDF={}: {:.1f}%\".format(args.tf, args.idf, f1_score))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
